<!DOCTYPE html>
<html>

<head>
  <meta charset="utf-8">
  <meta name="description"
        content="ARCH: Hierarchical Hybrid Learning for Long-Horizon Contact-Rich Robotic Assembly">
  <meta name="keywords" content="Robotic Manipulation, Structural Representation, Model-based Planning, Foundation Models">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>ARCH | Hierarchical Hybrid Learning for Long-Horizon Contact-Rich Robotic Assembly</title>


    <!-- Thumbnail for social media sharing -->
    <!-- <meta property="og:image" content="media/thumbnail.jpg"> -->

    <!-- Favicon -->
    <!-- <link rel="icon" href="media/thumbnail.jpg" type="image/jpeg"> -->

    <script>
        window.dataLayer = window.dataLayer || [];
    </script>

    <script>
        function updateInTheWild() {
            var task = document.getElementById("inthewild-video-menu").value;

            console.log("updateInTheWild", task)

            var video = document.getElementById("inthewild-video");
            video.src = "media/videos/" +
                task +
                ".m4v"
            video.play();
        }

        function updateBimanual() {
            var task = document.getElementById("bimanual-video-menu").value;

            console.log("updateBimanual", task)

            var video = document.getElementById("bimanual-video");
            video.src = "media/videos/1_" +
                task +
                ".mp4"
            video.play();
        }

        function updateClothes() {
            var task = document.getElementById("clothes-video-menu").value;

            console.log("updateclothes", task)

            var img = document.getElementById("clothes-img");
            img.src = "media/fold-strategies/" +
                task +
                ".jpeg"

            var video = document.getElementById("clothes-video");
            video.src = "media/videos/fold-" +
                task +
                ".mp4"
            video.play();
        }
    </script>


    <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">

    <link rel="stylesheet" href="./static/css/bulma.min.css">
    <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
    <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
    <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
    <link rel="stylesheet" href="./static/css/index.css">

    <link rel="stylesheet" href="./static/source_serif_4.css">
    <link rel="stylesheet" href="./static/source_sans_3.css">
    <link rel="stylesheet" href="./static/academicons.min.css">
    <link rel="stylesheet" href="./static/fontawesome/css/fontawesome.css">
    <link rel="stylesheet" href="./static/fontawesome/css/brands.css">
    <link rel="stylesheet" href="./static/fontawesome/css/light.css">


    <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
    <script defer src="./static/js/fontawesome.all.min.js"></script>
    <script src="./static/js/bulma-carousel.min.js"></script>
    <script src="./static/js/bulma-slider.min.js"></script>
    <script src="./static/js/index.js"></script>
</head>

<body onload="updateInTheWild();updateBimanual();">


<section class="hero">
  <div class="hero-body">
    <div class="container is-fullhd">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">ARCH: Hierarchical Hybrid Learning for Long-Horizon Contact-Rich Robotic Assembly</h1>
        <div class="is-size-5 publication-authors">
            <span class="author-block">
                <a target="_blank" href="https://web.stanford.edu/~jksun">Jiankai Sun</a><sup>1</sup>,
        
            </span>
            <span class="author-block">
                <a target="_blank" href="https://aidanreececurtis.com/">Aidan Curtis</a><sup>2</sup>,
            </span>
            <span class="author-block">
                <a target="_blank" href="https://qq456cvb.github.io/">Yang You</a><sup>1</sup>,
            </span>
            <span class="author-block">
                <a target="_blank" href="https://decayale.github.io/">Yan Xu</a><sup>3</sup>,
            </span>
            <span class="author-block">
                <a target="_blank" href="https://www.research.autodesk.com/people/michael-koehle/">Michael
                    Koehle</a><sup>4</sup>,
            </span>
            <span class="author-block">
                <a target="_blank" href="https://www.semanticscholar.org/author/O.-Shorinwa/116069035">Olao Shorinwa</a><sup>5</sup>,
            </span>
            <br>
            <span class="author-block">
                <a target="_blank" href="https://qianzhong-chen.github.io/">Qianzhong Chen</a><sup>1</sup>,
            </span>
            <span class="author-block">
                <a target="_blank" href="https://suninghuang19.github.io/">Suning Huang</a><sup>1</sup>,
            </span>
            <span class="author-block">
                <a target="_blank" href="https://scholar.google.com/citations?user=5JlEyTAAAAAJ&hl=en">Leonidas
                    Guibas</a><sup>1</sup>,
            </span>
            <span class="author-block">
                <a target="_blank" href="https://scholar.google.com/citations?user=S2vB4tAAAAAJ&hl=en">Sachin
                    Chitta</a><sup>4</sup>,
            </span>
            <span class="author-block">
                <a target="_blank" href="https://web.stanford.edu/~schwager/">Mac
                    Schwager</a><sup>1</sup>,
            </span>
            <span class="author-block">
                <a target="_blank" href="https://www.research.autodesk.com/people/hui-li/">Hui
                    Li</a><sup>4</sup>
            </span>
        </div>
        <div class="is-size-5 affiliation">
            <sup>1</sup>Stanford University
            <sup>2</sup>MIT
            <sup>3</sup>University of Michigan
            <sup>4</sup>Autodesk Research
            <sup>5</sup>Princeton University
        </div>
                        <br>
                        <div class="button-container">
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </section>

    <section class="hero teaser">
        <div class="container is-max-widescreen">
            <div class="hero-body">
                <div class="container">
                    <br>
                    <h2 class="subtitle has-text-centered">
                    </h2>
                </div>
            </div>
        </div>

        <div class="container is-max-widescreen">
            <div class="columns is-centered has-text-centered">
                <div class="column is-four-fifths">
                    <h2 class="title is-3">Abstract</h2>
                    <div class="content has-text-justified">
                        <p>
                            Generalizable long-horizon robotic assembly requires reasoning at multiple levels of abstraction. End-to-end imitation
                            learning (IL) has been proven a promising approach, but it requires a large amount of demonstration data for training
                            and often fails to meet the high-precision requirement of assembly tasks. Reinforcement Learning (RL) approaches have
                            succeeded in high-precision assembly tasks, but suffer from sample inefficiency and hence, are less competent at
                            long-horizon tasks. To address these challenges, we propose a hierarchical modular approach, named ARCH (Adaptive
                            Robotic Compositional Hierarchy), which enables long-horizon high-precision assembly in contact-rich settings. ARCH
                            employs a hierarchical planning framework, including a low-level primitive library of parameterized skills and a
                            high-level policy. The low-level primitive library includes essential skills for assembly tasks, such as grasping and
                            inserting. These primitives consist of both RL and model-based policies. The high-level policy, learned via IL from a
                            handful of demonstrations, selects the appropriate primitive skills and instantiates them with input parameters. We
                            extensively evaluate our approach in simulation and on a real robotic manipulation platform. We show that ARCH
                            generalizes well to unseen objects and outperforms baseline methods in terms of success rate and data efficiency.
                        </p>
                    </div>
                </div>
            </div>


            <hr class="rounded">
            <div class="rows">
                <h2 class="title is-3">Overview of ARCH</h2>
                <div class="column2">
                    <img src="media/figures/method.png" alt="method-imag" style="width:100%">
                </div>
                <div class="column2">
                    <img src="media/figures/overview.png" alt="method-image" style="width:100%">
                </div>
                <p class="content has-text-justified">
                    We propose a hierarchical framework for long-horizon robotic assembly. The high-level policy, which takes as input object pose from pose estimation and robot proprioception, and outputs a categorical distribution to select the best low-level primitive
                    as well as its continuous parameters, is obtained via imitation learning. The low-level policy executes the selected primitive using either an RL-based or a motion-planned (MP) policy. We train in simulation an RL policy for the contact-rich
                    portion of the task, e.g. insertion, based on force-torque feedback. We use the MP policies for primitives that are in free space, e.g. move.
                </p>
            </div>

            <hr class="rounded">
            <div class="rows">
                <h2 class="title is-3">Generalization to Unseen Objects</h2>
                <div class="columns">
                    <div class="column has-text-centered">
                        <div class="select is-rounded">
                            <select id="bimanual-video-menu" onchange="updateBimanual()">
          <option value="circle" selected="selected">Circle (Unseen)</option>
          <option value="doublesquare">Double Square (Unseen)</option>
          <option value="oval">Oval (Unseen)</option>
          <option value="3prong">3prong (Unseen)</option>
          <option value="hexagon">Hexagon (Seen)</option>
          <option value="star">Star (Unseen)</option>
          </select>
                        </div>
                    </div>
                </div>

                <div class="columns">
                    <div class="column has-text-centered">
                        <p style="text-align:center;">
                            <video id="bimanual-video" width="100%" height="100%" controls autoplay loop muted>
            <source src="media/videos/1_circle.mp4" type="video/mp4">
          </video>
                        </p>
                    </div>
                </div>
            </div>

    </section>
    </div>

    <footer class="footer">
        <div class="container">
            <div class="columns is-centered">
                <div class="column">
                    <div class="content has-text-centered">
                        <p>
                            Website template borrowed from <a href="https://nerfies.github.io">Nerfies</a>.
                        </p>
                    </div>
                </div>
            </div>
        </div>
    </footer>


</body>

</html>